{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"/media/ps/data/train/LQ/LQ/bdms/bdmask/workspace/models/JT/JT-imgs/2222/odd.jpg\", 0)\n",
    "img = cv2.resize(img, (2144, 3584))\n",
    "cv2.imwrite(\"/media/ps/data/train/LQ/LQ/bdms/bdmask/workspace/models/JT/JT-imgs/2222/odd-3584-2144.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.randint(0,10, (2,3,4))\n",
    "k,p,q = list(map(int, a.shape))\n",
    "k,p,q = map(int, a.shape)\n",
    "print(k, p, q)\n",
    "# print(k, p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(file):\n",
    "\n",
    "    with open(file, \"rb\") as f:\n",
    "        binary_data = f.read()\n",
    "\n",
    "    magic_number, ndims, dtype = np.frombuffer(binary_data, np.uint32, count=3, offset=0)\n",
    "    assert magic_number == 0xFCCFE2E2, f\"{file} not a tensor file.\"\n",
    "\n",
    "    dims = np.frombuffer(binary_data, np.uint32, count=ndims, offset=3 * 4)\n",
    "\n",
    "    if dtype == 0:\n",
    "        np_dtype = np.float32\n",
    "    elif dtype == 1:\n",
    "        np_dtype = np.float16\n",
    "    else:\n",
    "        assert False, f\"Unsupport dtype = {dtype}, can not convert to numpy dtype\"\n",
    "\n",
    "    return np.frombuffer(binary_data, np_dtype, offset=(ndims + 3) * 4).reshape(*dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"/media/ps/data/train/LQ/task/bdm/bdmask/workspace/models/JT/JT-imgs/2222/2222\"\n",
    "outpath = r'/media/ps/data/train/LQ/task/bdm/bdmask/workspace/models/JT/JT-imgs/2222/2222.jpg'\n",
    "img = load_tensor(file)\n",
    "img = img[0].transpose(1,2,0)\n",
    "# img = img.reshape(3584, 2144, 3)\n",
    "img.shape\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imwrite(outpath, img)\n",
    "\n",
    "# im.shape\n",
    "# cv2.imwrite(outpath, im)\n",
    "# plt.imshow(im,cmap=\"gray\")\n",
    "\n",
    "# plt.imsave(outpath, im, cmap=\"gray\")\n",
    "\n",
    "# print(im.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3648, 5472)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048*2048\n",
    "(3648, 5472)\n",
    "(3648, 5472)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87296"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mul(h, w):\n",
    "    list = [8, 16, 32, 64, 128]\n",
    "    sum = 0\n",
    "    for i in list:\n",
    "        sum += (int(h / i+0.5) * int(w / i+0.5))\n",
    "    return sum\n",
    "# mul(2048, 2048)\n",
    "mul(2048, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2048/8 * 2048 /8 + 2048/16 * 2048 /16 + 2048/32 * 2048 /32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(3648 / 64+0.5) * int(5472/64+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(3648 / 16+0.5) * int(5472/16+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(3648 / 128+0.5) * int(5472/128+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3648 / 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "311904+77976+19494+4902+1247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 2, 4],\n",
       "        [1, 2, 6]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "a = torch.randint(1, 10, (2,3))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randint(1, 10, (2,3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a- b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sub(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.add(a, b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = torch.randint(1, 10, (2,))\n",
    "ttt = ttt[..., None]\n",
    "ttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_locations(h, w, stride, device):\n",
    "    shifts_x = torch.arange(\n",
    "        0, w * stride, step=stride,\n",
    "        dtype=torch.float32, device=device\n",
    "    )       # [0,8,16,24,...,2040]\n",
    "    shifts_y = torch.arange(\n",
    "        0, h * stride, step=stride,\n",
    "        dtype=torch.float32, device=device\n",
    "    )       # [0,8,16,24,...,2040]\n",
    "    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)\n",
    "    shift_x = shift_x.reshape(-1)\n",
    "    shift_y = shift_y.reshape(-1)\n",
    "    # print(shift_x)\n",
    "    # print(shift_y)\n",
    "    locations = torch.stack((shift_x, shift_y), dim=1) + stride // 2\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 3648\n",
    "w = 5472\n",
    "strides = [8,16,32,64,128]\n",
    "device = \"cuda:3\"\n",
    "for stride in strides:\n",
    "    h_step = math.ceil(h / stride)\n",
    "    w_step = math.ceil(w / stride)\n",
    "    locations = compute_locations(h_step, w_step, stride, device)\n",
    "    print(h_step, w_step, stride, locations.shape)\n",
    "    print(locations[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts_y = torch.tensor([3,4,5,6,7])\n",
    "shifts_x = torch.tensor([2,3,3,4])\n",
    "yx, xy = torch.meshgrid(shifts_y, shifts_x)\n",
    "\n",
    "shift_x = xy.reshape(-1)\n",
    "shift_y = yx.reshape(-1)\n",
    "print(yx.shape, xy.shape)\n",
    "locations = torch.stack((shift_x, shift_y), dim=1) + stride // 2\n",
    "print(yx, xy, locations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "import os.path as osp\n",
    "import imagesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = r\"/media/ps/data/train/LQ/LQ/bdms/yolov7/datasets/coco128/images/train\"\n",
    "imps = glob(src + \"/*.jpg\")\n",
    "dic = []\n",
    "for idx, imp in enumerate(imps):\n",
    "    # print(imagesize.get(imp))\n",
    "    h, w  = imagesize.get(imp)\n",
    "    dic.append({\n",
    "        \"filename\":imp,\n",
    "        \"height\":h,\n",
    "        \"width\":w\n",
    "    })\n",
    "dataloader = torch.utils.data.DataLoader(dic)\n",
    "print(dataloader)\n",
    "for datas in dataloader:\n",
    "    print(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "a = torch.randint(1, 10, (1,1,2,4), dtype=torch.float32)\n",
    "coeffs = F.interpolate(a, scale_factor=4,\n",
    "                            mode='bilinear', align_corners=False)\n",
    "\n",
    "\n",
    "print(a[0,0,0], \"\\n\",coeffs[0,0,0], a.shape, coeffs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3555, 2117, 3)\n",
      "2144 3584\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "src  = r'/media/ps/data/train/LQ/task/bdm/bdmask/workspace/models/JT/JT-imgs/2222/odd.jpg'\n",
    "img = cv2.imread(src, 1)\n",
    "size = img.shape\n",
    "print(img.shape)\n",
    "new_h = (size[0] + 32) // 32 * 32\n",
    "new_w = (size[1] + 32) // 32 * 32\n",
    "print(new_w, new_h)\n",
    "# mat = np.array([\n",
    "#     [1, 0, (- new_w + size[1]) * 2.0],\n",
    "#     [0, 1, (- new_h + size[0]) * 2.0]\n",
    "# ], dtype=np.float32)\n",
    "\n",
    "mat = np.array([\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0]\n",
    "], dtype=np.float32)\n",
    "print(mat)\n",
    "nimg =  cv2.warpAffine(img, mat, (new_w, new_h), borderValue=(0,0,0))\n",
    "# nimg.shape\n",
    "# plt.imshow(nimg[..., ::-1])\n",
    "\n",
    "cv2.imwrite(r'/media/ps/data/train/LQ/task/bdm/bdmask/workspace/models/JT/JT-imgs/2222/222222222.jpg', nimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 ('adet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bc1da48524977198160280456b310d34a88700418ee6197d48ccf2192b413b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
